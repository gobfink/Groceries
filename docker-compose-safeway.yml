version: '3.5'
services:
  safeway:
     healthcheck:
       test: ["CMD", "/opt/healthcheck.sh", "safeway", "groceries"]
       interval: 30s
       start_period: 90s
       retries: 1
     volumes:
     - ./scrapy/code:/code
     build: 
       context: scrapy/
       dockerfile: Dockerfile.selenium.runtime
       shm_size: '4gb'
     hostname: safeway-groceries
     environment: 
        - "PYTHONPATH=/code/groceries"
     networks:
     - backend
     entrypoint: "/usr/local/bin/scrapy runspider groceryScraper.py"
     working_dir: /code/groceries/spiders/safeway
     restart: unless-stopped
  safeway-urls:
     healthcheck:
       test: ["CMD", "/opt/healthcheck.sh", "safeway", "url"]
       interval: 60s
       start_period: 200s
       retries: 1
     volumes:
     - ./scrapy/code:/code
     build: 
       context: scrapy/
       dockerfile: Dockerfile.selenium.runtime
       shm_size: '6gb'
     hostname: safeway-urls
     environment: 
        - "PYTHONPATH=/code/groceries"
     networks:
     - backend
     entrypoint: "/usr/local/bin/scrapy runspider urlScraper.py"
     working_dir: /code/groceries/spiders/safeway
     restart: unless-stopped
  safeway-groceries:
     healthcheck:
       test: ["CMD", "/opt/healthcheck.sh", "safeway", "grocery"]
       interval: 60s
       start_period: 200s
       retries: 1
     volumes:
     - ./scrapy/code:/code
     build: 
       context: scrapy/
       dockerfile: Dockerfile.selenium.runtime
       shm_size: '6gb'
     hostname: safeway-groceries
     environment: 
        - "PYTHONPATH=/code/groceries"
     networks:
     - backend
     entrypoint: "/usr/local/bin/scrapy runspider groceryScraper.py"
     working_dir: /code/groceries/spiders/safeway
     restart: unless-stopped
networks:
  backend:
